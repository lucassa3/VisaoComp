{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto de estabilização de video\n",
    "\n",
    "Projeto em que, dado o conhecimento adquirido sobre fluxo ótico de imagens, criar um estabilizador de webcam compensando deslocamentos da camera ou do agente que a camera esta capturando\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "\n",
    "#!pip install opencv-python\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "print(cv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira versão: cálculo do deslocamento com optical flow de determinados pontos da imagem\n",
    "\n",
    "A primeira versão do código utiliza-se de um selecionador de boas features para serem rastreadas na imagem, calculando o fluxo ótico baseado no movimento delas ao longo da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametriza a funcao do OpenCV\n",
    "dt_params = dict( maxCorners = 100,\n",
    "                  qualityLevel = 0.3,\n",
    "                  minDistance = 7,\n",
    "                  blockSize = 7 )\n",
    "\n",
    "# Parametriza o Lucas-Kanade\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Gera cores de forma aleatória\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "\n",
    "captura = cv.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "previous = captura.read()[1]\n",
    "previous_gray = cv.cvtColor(previous, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(previous_gray, mask = None, **dt_params)\n",
    "\n",
    "# Cria uma máscara para imprimir o rastro.\n",
    "mask = np.zeros_like(previous)\n",
    "\n",
    "media = np.array([0.0,0.0])\n",
    "\n",
    "while(1):\n",
    "    ret, frame = captura.read()\n",
    "    \n",
    "    actual_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcula o Fluxo Otico\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(previous_gray, actual_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Seleciona somente os melhores pontos\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    \n",
    "    delta = good_new - good_old\n",
    "    media -= np.mean(delta, axis=0)\n",
    "    \n",
    "    # Desenha as trilhas para cada ponto em p1 e p0\n",
    "    for i,(new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        frame = cv.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    \n",
    "    img = frame\n",
    "    \n",
    "    img_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rows, cols = img_gray.shape\n",
    "    \n",
    "    M = np.array([[1, 0, media[0]], [0, 1, media[1]]], dtype=np.float32)\n",
    "    img_shifted = cv.warpAffine(img, M, (cols,rows))  # Terceiro argumento é o tamanho da imagem resultante.\n",
    "    \n",
    "    cv.imshow(\"Video\", img_shifted)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    \n",
    "captura.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O problema desta primeira versão é que o uso de pontos pre determinados da imagem para calcular o fluxo optico da imagem pode ser uma ma escolha, uma vez que depende-se do algoritmo para fazer a escolha dos pontos. Isto pode resultar em escolha de features que simplesmente não estão em movimento, prejudicando o calculo do fluxo otico medio da imagem, assim como o deslocamento de pontos que inevitavelmente vão sair do frame, perdendo a informação destes fluxos ópticos. Ainda ha erros associados ao algoritmo de captura de features, uma vez que alguns pontos de features que ja sairam do frame permanecem calculados como se estivessem ainda na borda da mesma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda versão: calculo do dense optical flow de uma janela da imagem\n",
    "\n",
    "A segunda versão utiliza-se do calculo do fluxo otico geral da tela. Ao inves de depender de algumas features rastreaveis, o metodo de farneback calcula o fluxo otico de todos os pontos do frame, e para cada pixel, frame a frame, determina-se um vetor com direção e magnitude na direção do movimento observado entre frames. O algoritmo abaixo utiliza-se do calculo do fluxo otico denso de uma janela central "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "previous = captura.read()[1]\n",
    "previous_gray = cv.cvtColor(previous, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "media = np.array([0.0,0.0])\n",
    "\n",
    "win_size = 120\n",
    "\n",
    "while(1):\n",
    "    ret, frame = captura.read()\n",
    "    \n",
    "    actual_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calcula o Fluxo Otico\n",
    "    flow = cv.calcOpticalFlowFarneback(previous_gray[int((previous_gray.shape[0]/2)-win_size):int((previous_gray.shape[0]/2)+win_size)][int((previous_gray.shape[1]/2)-win_size):int((previous_gray.shape[1]/2)+win_size)], \n",
    "                                       actual_gray[int((previous_gray.shape[0]/2)-win_size):int((previous_gray.shape[0]/2)+win_size)][int((previous_gray.shape[1]/2)-win_size):int((previous_gray.shape[1]/2)+win_size)], \n",
    "                                       None, 0.5, 3, 5, 3, 5, 1.2, 0)\n",
    "    media_x = np.mean(flow[...,0])\n",
    "    media_y = np.mean(flow[...,1])\n",
    "    media -= [media_x, media_y]\n",
    "\n",
    "    img = frame\n",
    "    \n",
    "    img_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rows, cols = img_gray.shape\n",
    "    \n",
    "    M = np.array([[1, 0, media[0]], [0, 1, media[1]]], dtype=np.float32)\n",
    "    img_shifted = cv.warpAffine(img, M, (cols,rows))  # Terceiro argumento é o tamanho da imagem resultante.\n",
    "    \n",
    "    cv.imshow(\"Video\", img_shifted)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray.copy()\n",
    "\n",
    "\n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    \n",
    "captura.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimizando a estabilizacao cortando as bordas:\n",
    "\n",
    "Uma implementação que visa contornar o aparecimento das bordas pretas foi desenvolvido abaixo. O algoritmo tenta compensaras bordas pretas (e a consequente perda de proporcao da imagem) cortando a imagem no outro eixo tal que a mesma mantenha a proporção, mas cause um efeito de zoom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "captura = cv.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "previous = captura.read()[1]\n",
    "previous_gray = cv.cvtColor(previous, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "media = np.array([0.0,0.0])\n",
    "\n",
    "win_size = 120\n",
    "\n",
    "while(1):\n",
    "    ret, frame = captura.read()\n",
    "    \n",
    "    actual_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calcula o Fluxo Otico\n",
    "    flow = cv.calcOpticalFlowFarneback(previous_gray[int((previous_gray.shape[0]/2)-win_size):int((previous_gray.shape[0]/2)+win_size)][int((previous_gray.shape[1]/2)-win_size):int((previous_gray.shape[1]/2)+win_size)], \n",
    "                                       actual_gray[int((previous_gray.shape[0]/2)-win_size):int((previous_gray.shape[0]/2)+win_size)][int((previous_gray.shape[1]/2)-win_size):int((previous_gray.shape[1]/2)+win_size)], \n",
    "                                       None, 0.5, 3, 5, 3, 5, 1.2, 0)\n",
    "    media_x = np.mean(flow[...,0])\n",
    "    media_y = np.mean(flow[...,1])\n",
    "    media -= [media_x, media_y]\n",
    "\n",
    "    img = frame\n",
    "    \n",
    "    \n",
    "    \n",
    "    if media[0] > 0:\n",
    "        img = img[:,0:img.shape[1]-int(media[0])]\n",
    "        \n",
    "    else:\n",
    "        img = img[:,-int(media[0]):img.shape[1]]\n",
    "        \n",
    "    if media[1] > 0:\n",
    "        img = img[0:img.shape[0]-int(media[1]),:]\n",
    "        \n",
    "    else:\n",
    "        img = img[-int(media[1]):img.shape[0],:]\n",
    "    \n",
    "    cut_0 = img.shape[0] - (3/4)*img.shape[1]\n",
    "    cut_1 = img.shape[1] - (4/3)*img.shape[0]\n",
    "    \n",
    "    if cut_0 > 0:\n",
    "        img = img[int(cut_0/2):img.shape[0]-int(cut_0/2),:]\n",
    "        \n",
    "    if cut_1 > 0:\n",
    "        img = img[:,int(cut_1/2):img.shape[0]-int(cut_1/2)]\n",
    "    \n",
    "    \n",
    "    img_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    rows, cols = img_gray.shape\n",
    "    \n",
    "    cv.imshow(\"Video\", img)\n",
    "    \n",
    "    # Atualiza a imagem anterior com a imagem atual e copia os pontos.\n",
    "    previous_gray = actual_gray.copy()\n",
    "\n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    \n",
    "captura.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
